{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Head poses Model Training\n",
    "\n",
    "Neural Network model for a quick Head Pose estimation, using just facial points as input. The model was made for real-time control of a Pan-Tilt camera using face movements as the control signal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies, set random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(14)\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.layers import Dropout \n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras import regularizers \n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7314, 61)\n"
     ]
    }
   ],
   "source": [
    "dfCenter = pd.read_csv('datasets/face_center.csv')\n",
    "dfCenter2 = pd.read_csv('datasets/face_center2.csv')\n",
    "dfCenter3 = pd.read_csv('datasets/face_center3.csv')\n",
    "dfCenter = dfCenter.append(dfCenter2, ignore_index = True).append(dfCenter3, ignore_index = True)\n",
    "\n",
    "dfRight = pd.read_csv('datasets/face_right.csv')\n",
    "dfRight2 = pd.read_csv('datasets/face_right2.csv')\n",
    "dfRight3 = pd.read_csv('datasets/face_right3.csv')\n",
    "dfRight4 = pd.read_csv('datasets/face_right4.csv')\n",
    "dfRight = dfRight.append(dfRight2, ignore_index = True).append(dfRight3, ignore_index = True).append(dfRight4, ignore_index = True)\n",
    "\n",
    "dfLeft = pd.read_csv('datasets/face_left.csv')\n",
    "dfLeft2 = pd.read_csv('datasets/face_left2.csv')\n",
    "dfLeft3 = pd.read_csv('datasets/face_left3.csv')\n",
    "dfLeft4 = pd.read_csv('datasets/face_left4.csv')\n",
    "dfLeft5 = pd.read_csv('datasets/face_left5.csv')\n",
    "dfLeft = dfLeft.append(dfLeft2, ignore_index = True).append(dfLeft3, ignore_index = True).append(dfLeft4, ignore_index = True).append(dfLeft5, ignore_index = True)\n",
    "\n",
    "dfUp = pd.read_csv('datasets/face_up.csv')\n",
    "dfDown = pd.read_csv('datasets/face_down.csv')\n",
    "dfUpRight = pd.read_csv('datasets/face_up-right.csv')\n",
    "dfUpLeft = pd.read_csv('datasets/face_up-left.csv')\n",
    "dfDownRight = pd.read_csv('datasets/face_down-right.csv')\n",
    "\n",
    "dfDownLeft = pd.read_csv('datasets/face_down-left.csv')\n",
    "dfDownLeft2 = pd.read_csv('datasets/face_down-left2.csv')\n",
    "dfDownLeft3 = pd.read_csv('datasets/face_down-left3.csv')\n",
    "dfDownLeft = dfDownLeft.append(dfDownLeft2, ignore_index = True).append(dfDownLeft3, ignore_index = True)\n",
    "\n",
    "columns = list(dfCenter)\n",
    "\n",
    "dfCenter['RESULT'] = 0\n",
    "dfRight['RESULT'] = 1\n",
    "dfLeft['RESULT'] = 2\n",
    "dfUp['RESULT'] = 3\n",
    "dfDown['RESULT'] = 4\n",
    "dfUpRight['RESULT'] = 5\n",
    "dfUpLeft['RESULT'] = 6\n",
    "dfDownRight['RESULT'] = 7\n",
    "dfDownLeft['RESULT'] = 8\n",
    "\n",
    "\n",
    "df = dfCenter.append(dfRight, ignore_index=True).append(dfLeft, ignore_index = True)\n",
    "df = df.append(dfUp, ignore_index = True).append(dfDown, ignore_index = True)\n",
    "df = df.append(dfUpRight, ignore_index = True).append(dfUpLeft, ignore_index = True)\n",
    "df = df.append(dfDownRight, ignore_index = True).append(dfDownLeft, ignore_index = True)\n",
    "\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>RESULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.946330</td>\n",
       "      <td>0.840339</td>\n",
       "      <td>0.756160</td>\n",
       "      <td>0.720585</td>\n",
       "      <td>0.707754</td>\n",
       "      <td>0.716760</td>\n",
       "      <td>0.797062</td>\n",
       "      <td>0.852249</td>\n",
       "      <td>0.892855</td>\n",
       "      <td>0.873837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227869</td>\n",
       "      <td>0.254465</td>\n",
       "      <td>0.322255</td>\n",
       "      <td>0.432351</td>\n",
       "      <td>0.492460</td>\n",
       "      <td>0.499847</td>\n",
       "      <td>0.494317</td>\n",
       "      <td>0.475419</td>\n",
       "      <td>0.454395</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.856706</td>\n",
       "      <td>0.758474</td>\n",
       "      <td>0.642529</td>\n",
       "      <td>0.584934</td>\n",
       "      <td>0.602656</td>\n",
       "      <td>0.673690</td>\n",
       "      <td>0.769424</td>\n",
       "      <td>0.845610</td>\n",
       "      <td>0.860791</td>\n",
       "      <td>0.847841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259727</td>\n",
       "      <td>0.233466</td>\n",
       "      <td>0.293848</td>\n",
       "      <td>0.394922</td>\n",
       "      <td>0.456411</td>\n",
       "      <td>0.488397</td>\n",
       "      <td>0.513183</td>\n",
       "      <td>0.507366</td>\n",
       "      <td>0.488397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.878858</td>\n",
       "      <td>0.760248</td>\n",
       "      <td>0.657293</td>\n",
       "      <td>0.598558</td>\n",
       "      <td>0.605994</td>\n",
       "      <td>0.665656</td>\n",
       "      <td>0.771598</td>\n",
       "      <td>0.842121</td>\n",
       "      <td>0.852072</td>\n",
       "      <td>0.811534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261712</td>\n",
       "      <td>0.229537</td>\n",
       "      <td>0.283921</td>\n",
       "      <td>0.379951</td>\n",
       "      <td>0.441522</td>\n",
       "      <td>0.459073</td>\n",
       "      <td>0.464209</td>\n",
       "      <td>0.486379</td>\n",
       "      <td>0.472645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.896369</td>\n",
       "      <td>0.769889</td>\n",
       "      <td>0.679754</td>\n",
       "      <td>0.600755</td>\n",
       "      <td>0.615911</td>\n",
       "      <td>0.681689</td>\n",
       "      <td>0.771598</td>\n",
       "      <td>0.842121</td>\n",
       "      <td>0.852072</td>\n",
       "      <td>0.811534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261712</td>\n",
       "      <td>0.230681</td>\n",
       "      <td>0.283921</td>\n",
       "      <td>0.379951</td>\n",
       "      <td>0.441522</td>\n",
       "      <td>0.482027</td>\n",
       "      <td>0.486921</td>\n",
       "      <td>0.501315</td>\n",
       "      <td>0.492836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.889466</td>\n",
       "      <td>0.769424</td>\n",
       "      <td>0.670478</td>\n",
       "      <td>0.582623</td>\n",
       "      <td>0.592269</td>\n",
       "      <td>0.657063</td>\n",
       "      <td>0.769424</td>\n",
       "      <td>0.823298</td>\n",
       "      <td>0.837595</td>\n",
       "      <td>0.824935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259727</td>\n",
       "      <td>0.233466</td>\n",
       "      <td>0.293848</td>\n",
       "      <td>0.394922</td>\n",
       "      <td>0.451059</td>\n",
       "      <td>0.465194</td>\n",
       "      <td>0.490052</td>\n",
       "      <td>0.485071</td>\n",
       "      <td>0.488397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.946330  0.840339  0.756160  0.720585  0.707754  0.716760  0.797062   \n",
       "1  0.856706  0.758474  0.642529  0.584934  0.602656  0.673690  0.769424   \n",
       "2  0.878858  0.760248  0.657293  0.598558  0.605994  0.665656  0.771598   \n",
       "3  0.896369  0.769889  0.679754  0.600755  0.615911  0.681689  0.771598   \n",
       "4  0.889466  0.769424  0.670478  0.582623  0.592269  0.657063  0.769424   \n",
       "\n",
       "          7         8         9   ...          51        52        53  \\\n",
       "0  0.852249  0.892855  0.873837   ...    0.227869  0.254465  0.322255   \n",
       "1  0.845610  0.860791  0.847841   ...    0.259727  0.233466  0.293848   \n",
       "2  0.842121  0.852072  0.811534   ...    0.261712  0.229537  0.283921   \n",
       "3  0.842121  0.852072  0.811534   ...    0.261712  0.230681  0.283921   \n",
       "4  0.823298  0.837595  0.824935   ...    0.259727  0.233466  0.293848   \n",
       "\n",
       "         54        55        56        57        58        59  RESULT  \n",
       "0  0.432351  0.492460  0.499847  0.494317  0.475419  0.454395       0  \n",
       "1  0.394922  0.456411  0.488397  0.513183  0.507366  0.488397       0  \n",
       "2  0.379951  0.441522  0.459073  0.464209  0.486379  0.472645       0  \n",
       "3  0.379951  0.441522  0.482027  0.486921  0.501315  0.492836       0  \n",
       "4  0.394922  0.451059  0.465194  0.490052  0.485071  0.488397       0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input data and desired output, and then split training and test observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[columns]\n",
    "y = df['RESULT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=14)\n",
    "\n",
    "X_train = np.array(X_train).astype('float32')\n",
    "X_test = np.array(X_test).astype('float32')\n",
    "\n",
    "n_classes = 9\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(60,)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               7808      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 76,425\n",
      "Trainable params: 75,657\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.00125), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5119 samples, validate on 2195 samples\n",
      "Epoch 1/100\n",
      "5119/5119 [==============================] - 1s 161us/step - loss: 0.1224 - acc: 0.9576 - val_loss: 0.1069 - val_acc: 0.9658\n",
      "Epoch 2/100\n",
      "5119/5119 [==============================] - 1s 155us/step - loss: 0.1199 - acc: 0.9578 - val_loss: 0.1176 - val_acc: 0.9567\n",
      "Epoch 3/100\n",
      "5119/5119 [==============================] - 1s 153us/step - loss: 0.1132 - acc: 0.9598 - val_loss: 0.0994 - val_acc: 0.9626\n",
      "Epoch 4/100\n",
      "5119/5119 [==============================] - 1s 168us/step - loss: 0.1174 - acc: 0.9603 - val_loss: 0.1314 - val_acc: 0.9581\n",
      "Epoch 5/100\n",
      "5119/5119 [==============================] - 1s 172us/step - loss: 0.1163 - acc: 0.9582 - val_loss: 0.0872 - val_acc: 0.9686\n",
      "Epoch 6/100\n",
      "5119/5119 [==============================] - 1s 162us/step - loss: 0.1240 - acc: 0.9562 - val_loss: 0.0945 - val_acc: 0.9622\n",
      "Epoch 7/100\n",
      "5119/5119 [==============================] - 1s 170us/step - loss: 0.1222 - acc: 0.9557 - val_loss: 0.0779 - val_acc: 0.9704\n",
      "Epoch 8/100\n",
      "5119/5119 [==============================] - 1s 203us/step - loss: 0.1248 - acc: 0.9570 - val_loss: 0.0776 - val_acc: 0.9731\n",
      "Epoch 9/100\n",
      "5119/5119 [==============================] - 1s 190us/step - loss: 0.1206 - acc: 0.9553 - val_loss: 0.0772 - val_acc: 0.9740\n",
      "Epoch 10/100\n",
      "5119/5119 [==============================] - 1s 190us/step - loss: 0.1190 - acc: 0.9598 - val_loss: 0.0739 - val_acc: 0.9745\n",
      "Epoch 11/100\n",
      "5119/5119 [==============================] - 1s 198us/step - loss: 0.1127 - acc: 0.9562 - val_loss: 0.0849 - val_acc: 0.9690\n",
      "Epoch 12/100\n",
      "5119/5119 [==============================] - 1s 195us/step - loss: 0.1215 - acc: 0.9564 - val_loss: 0.0877 - val_acc: 0.9690\n",
      "Epoch 13/100\n",
      "5119/5119 [==============================] - 1s 188us/step - loss: 0.1205 - acc: 0.9555 - val_loss: 0.0791 - val_acc: 0.9745\n",
      "Epoch 14/100\n",
      "5119/5119 [==============================] - 1s 200us/step - loss: 0.1108 - acc: 0.9639 - val_loss: 0.0750 - val_acc: 0.9727\n",
      "Epoch 15/100\n",
      "5119/5119 [==============================] - 1s 193us/step - loss: 0.1109 - acc: 0.9646 - val_loss: 0.0781 - val_acc: 0.9690\n",
      "Epoch 16/100\n",
      "5119/5119 [==============================] - 1s 200us/step - loss: 0.1249 - acc: 0.9553 - val_loss: 0.0784 - val_acc: 0.9695\n",
      "Epoch 17/100\n",
      "5119/5119 [==============================] - 1s 201us/step - loss: 0.1185 - acc: 0.9590 - val_loss: 0.0768 - val_acc: 0.9713\n",
      "Epoch 18/100\n",
      "5119/5119 [==============================] - 1s 191us/step - loss: 0.1190 - acc: 0.9594 - val_loss: 0.0740 - val_acc: 0.9740\n",
      "Epoch 19/100\n",
      "5119/5119 [==============================] - 1s 190us/step - loss: 0.1142 - acc: 0.9609 - val_loss: 0.0929 - val_acc: 0.9645\n",
      "Epoch 20/100\n",
      "5119/5119 [==============================] - 1s 199us/step - loss: 0.1116 - acc: 0.9619 - val_loss: 0.0706 - val_acc: 0.9786\n",
      "Epoch 21/100\n",
      "5119/5119 [==============================] - 1s 196us/step - loss: 0.1197 - acc: 0.9603 - val_loss: 0.1452 - val_acc: 0.9481\n",
      "Epoch 22/100\n",
      "5119/5119 [==============================] - 1s 190us/step - loss: 0.1148 - acc: 0.9584 - val_loss: 0.1382 - val_acc: 0.9481\n",
      "Epoch 23/100\n",
      "5119/5119 [==============================] - 1s 212us/step - loss: 0.1307 - acc: 0.9486 - val_loss: 0.0945 - val_acc: 0.9686\n",
      "Epoch 24/100\n",
      "5119/5119 [==============================] - 1s 199us/step - loss: 0.1102 - acc: 0.9633 - val_loss: 0.0814 - val_acc: 0.9695\n",
      "Epoch 25/100\n",
      "5119/5119 [==============================] - 1s 201us/step - loss: 0.1163 - acc: 0.9570 - val_loss: 0.0930 - val_acc: 0.9617\n",
      "Epoch 26/100\n",
      "5119/5119 [==============================] - 1s 214us/step - loss: 0.1154 - acc: 0.9588 - val_loss: 0.0971 - val_acc: 0.9645\n",
      "Epoch 27/100\n",
      "5119/5119 [==============================] - 1s 210us/step - loss: 0.1126 - acc: 0.9607 - val_loss: 0.1447 - val_acc: 0.9508\n",
      "Epoch 28/100\n",
      "5119/5119 [==============================] - 1s 207us/step - loss: 0.1144 - acc: 0.9609 - val_loss: 0.0832 - val_acc: 0.9686\n",
      "Epoch 29/100\n",
      "5119/5119 [==============================] - 1s 218us/step - loss: 0.1175 - acc: 0.9582 - val_loss: 0.0829 - val_acc: 0.9699\n",
      "Epoch 30/100\n",
      "5119/5119 [==============================] - 1s 216us/step - loss: 0.1228 - acc: 0.9566 - val_loss: 0.0772 - val_acc: 0.9695\n",
      "Epoch 31/100\n",
      "5119/5119 [==============================] - 1s 210us/step - loss: 0.1155 - acc: 0.9594 - val_loss: 0.0851 - val_acc: 0.9681\n",
      "Epoch 32/100\n",
      "5119/5119 [==============================] - 1s 219us/step - loss: 0.1265 - acc: 0.9566 - val_loss: 0.0757 - val_acc: 0.9740\n",
      "Epoch 33/100\n",
      "5119/5119 [==============================] - 1s 190us/step - loss: 0.1201 - acc: 0.9613 - val_loss: 0.0840 - val_acc: 0.9699\n",
      "Epoch 34/100\n",
      "5119/5119 [==============================] - 1s 194us/step - loss: 0.1260 - acc: 0.9519 - val_loss: 0.0920 - val_acc: 0.9636\n",
      "Epoch 35/100\n",
      "5119/5119 [==============================] - 1s 203us/step - loss: 0.1100 - acc: 0.9603 - val_loss: 0.0812 - val_acc: 0.9704\n",
      "Epoch 36/100\n",
      "5119/5119 [==============================] - 1s 196us/step - loss: 0.1252 - acc: 0.9545 - val_loss: 0.1316 - val_acc: 0.9526\n",
      "Epoch 37/100\n",
      "5119/5119 [==============================] - 1s 203us/step - loss: 0.1242 - acc: 0.9535 - val_loss: 0.0950 - val_acc: 0.9599\n",
      "Epoch 38/100\n",
      "5119/5119 [==============================] - 1s 198us/step - loss: 0.1221 - acc: 0.9568 - val_loss: 0.0834 - val_acc: 0.9690\n",
      "Epoch 39/100\n",
      "5119/5119 [==============================] - 1s 190us/step - loss: 0.1200 - acc: 0.9566 - val_loss: 0.0871 - val_acc: 0.9690\n",
      "Epoch 40/100\n",
      "5119/5119 [==============================] - 1s 194us/step - loss: 0.1289 - acc: 0.9555 - val_loss: 0.0892 - val_acc: 0.9663\n",
      "Epoch 41/100\n",
      "5119/5119 [==============================] - 1s 196us/step - loss: 0.1255 - acc: 0.9576 - val_loss: 0.1498 - val_acc: 0.9440\n",
      "Epoch 42/100\n",
      "5119/5119 [==============================] - 1s 193us/step - loss: 0.1143 - acc: 0.9594 - val_loss: 0.0703 - val_acc: 0.9763\n",
      "Epoch 43/100\n",
      "5119/5119 [==============================] - 1s 203us/step - loss: 0.1217 - acc: 0.9586 - val_loss: 0.0753 - val_acc: 0.9754\n",
      "Epoch 44/100\n",
      "5119/5119 [==============================] - 1s 205us/step - loss: 0.1218 - acc: 0.9580 - val_loss: 0.0941 - val_acc: 0.9654\n",
      "Epoch 45/100\n",
      "5119/5119 [==============================] - 1s 191us/step - loss: 0.1142 - acc: 0.9596 - val_loss: 0.0831 - val_acc: 0.9658\n",
      "Epoch 46/100\n",
      "5119/5119 [==============================] - 1s 195us/step - loss: 0.1170 - acc: 0.9576 - val_loss: 0.0799 - val_acc: 0.9740\n",
      "Epoch 47/100\n",
      "5119/5119 [==============================] - 1s 198us/step - loss: 0.1175 - acc: 0.9551 - val_loss: 0.0971 - val_acc: 0.9640\n",
      "Epoch 48/100\n",
      "5119/5119 [==============================] - 1s 193us/step - loss: 0.1098 - acc: 0.9621 - val_loss: 0.0875 - val_acc: 0.9663\n",
      "Epoch 49/100\n",
      "5119/5119 [==============================] - 1s 197us/step - loss: 0.1273 - acc: 0.9555 - val_loss: 0.0738 - val_acc: 0.9745\n",
      "Epoch 50/100\n",
      "5119/5119 [==============================] - 1s 206us/step - loss: 0.1217 - acc: 0.9572 - val_loss: 0.0794 - val_acc: 0.9681\n",
      "Epoch 51/100\n",
      "5119/5119 [==============================] - 1s 197us/step - loss: 0.1257 - acc: 0.9545 - val_loss: 0.0827 - val_acc: 0.9731\n",
      "Epoch 52/100\n",
      "5119/5119 [==============================] - 1s 198us/step - loss: 0.1206 - acc: 0.9564 - val_loss: 0.1147 - val_acc: 0.9617\n",
      "Epoch 53/100\n",
      "5119/5119 [==============================] - 1s 192us/step - loss: 0.1024 - acc: 0.9621 - val_loss: 0.0958 - val_acc: 0.9645\n",
      "Epoch 54/100\n",
      "5119/5119 [==============================] - 1s 190us/step - loss: 0.1146 - acc: 0.9600 - val_loss: 0.0767 - val_acc: 0.9736\n",
      "Epoch 55/100\n",
      "5119/5119 [==============================] - 1s 201us/step - loss: 0.1177 - acc: 0.9570 - val_loss: 0.0818 - val_acc: 0.9722\n",
      "Epoch 56/100\n",
      "5119/5119 [==============================] - 1s 197us/step - loss: 0.1144 - acc: 0.9578 - val_loss: 0.1388 - val_acc: 0.9431\n",
      "Epoch 57/100\n",
      "5119/5119 [==============================] - 1s 202us/step - loss: 0.1127 - acc: 0.9596 - val_loss: 0.0861 - val_acc: 0.9667\n",
      "Epoch 58/100\n",
      "5119/5119 [==============================] - 1s 208us/step - loss: 0.1150 - acc: 0.9633 - val_loss: 0.1040 - val_acc: 0.9626\n",
      "Epoch 59/100\n",
      "5119/5119 [==============================] - 1s 192us/step - loss: 0.1053 - acc: 0.9609 - val_loss: 0.0878 - val_acc: 0.9667\n",
      "Epoch 60/100\n",
      "5119/5119 [==============================] - 1s 191us/step - loss: 0.1211 - acc: 0.9564 - val_loss: 0.0777 - val_acc: 0.9727\n",
      "Epoch 61/100\n",
      "5119/5119 [==============================] - 1s 200us/step - loss: 0.1189 - acc: 0.9570 - val_loss: 0.0945 - val_acc: 0.9654\n",
      "Epoch 62/100\n",
      "5119/5119 [==============================] - 1s 192us/step - loss: 0.1066 - acc: 0.9633 - val_loss: 0.0802 - val_acc: 0.9681\n",
      "Epoch 63/100\n",
      "5119/5119 [==============================] - 1s 192us/step - loss: 0.1067 - acc: 0.9617 - val_loss: 0.0748 - val_acc: 0.9763\n",
      "Epoch 64/100\n",
      "5119/5119 [==============================] - 1s 211us/step - loss: 0.1080 - acc: 0.9588 - val_loss: 0.0705 - val_acc: 0.9768\n",
      "Epoch 65/100\n",
      "5119/5119 [==============================] - 1s 200us/step - loss: 0.1081 - acc: 0.9619 - val_loss: 0.0664 - val_acc: 0.9795\n",
      "Epoch 66/100\n",
      "5119/5119 [==============================] - 1s 193us/step - loss: 0.1127 - acc: 0.9600 - val_loss: 0.1200 - val_acc: 0.9549\n",
      "Epoch 67/100\n",
      "5119/5119 [==============================] - 1s 200us/step - loss: 0.1119 - acc: 0.9607 - val_loss: 0.0853 - val_acc: 0.9663\n",
      "Epoch 68/100\n",
      "5119/5119 [==============================] - 1s 190us/step - loss: 0.1131 - acc: 0.9611 - val_loss: 0.0829 - val_acc: 0.9672\n",
      "Epoch 69/100\n",
      "5119/5119 [==============================] - 1s 191us/step - loss: 0.1179 - acc: 0.9580 - val_loss: 0.0817 - val_acc: 0.9690\n",
      "Epoch 70/100\n",
      "5119/5119 [==============================] - 1s 203us/step - loss: 0.1021 - acc: 0.9629 - val_loss: 0.0751 - val_acc: 0.9727\n",
      "Epoch 71/100\n",
      "5119/5119 [==============================] - 1s 209us/step - loss: 0.1118 - acc: 0.9629 - val_loss: 0.0832 - val_acc: 0.9681\n",
      "Epoch 72/100\n",
      "5119/5119 [==============================] - 1s 196us/step - loss: 0.1113 - acc: 0.9611 - val_loss: 0.0848 - val_acc: 0.9690\n",
      "Epoch 73/100\n",
      "5119/5119 [==============================] - 1s 202us/step - loss: 0.1263 - acc: 0.9580 - val_loss: 0.0773 - val_acc: 0.9740\n",
      "Epoch 74/100\n",
      "5119/5119 [==============================] - 1s 192us/step - loss: 0.1271 - acc: 0.9570 - val_loss: 0.0880 - val_acc: 0.9677\n",
      "Epoch 75/100\n",
      "5119/5119 [==============================] - 1s 193us/step - loss: 0.1209 - acc: 0.9560 - val_loss: 0.0928 - val_acc: 0.9713\n",
      "Epoch 76/100\n",
      "5119/5119 [==============================] - 1s 200us/step - loss: 0.1012 - acc: 0.9644 - val_loss: 0.0821 - val_acc: 0.9667\n",
      "Epoch 77/100\n",
      "5119/5119 [==============================] - 1s 194us/step - loss: 0.1112 - acc: 0.9570 - val_loss: 0.0757 - val_acc: 0.9736\n",
      "Epoch 78/100\n",
      "5119/5119 [==============================] - 1s 210us/step - loss: 0.1037 - acc: 0.9623 - val_loss: 0.1016 - val_acc: 0.9649\n",
      "Epoch 79/100\n",
      "5119/5119 [==============================] - 1s 209us/step - loss: 0.1085 - acc: 0.9623 - val_loss: 0.0769 - val_acc: 0.9740\n",
      "Epoch 80/100\n",
      "5119/5119 [==============================] - 1s 195us/step - loss: 0.1136 - acc: 0.9564 - val_loss: 0.0821 - val_acc: 0.9708\n",
      "Epoch 81/100\n",
      "5119/5119 [==============================] - 1s 194us/step - loss: 0.1201 - acc: 0.9596 - val_loss: 0.0961 - val_acc: 0.9654\n",
      "Epoch 82/100\n",
      "5119/5119 [==============================] - 1s 202us/step - loss: 0.1045 - acc: 0.9621 - val_loss: 0.1001 - val_acc: 0.9636\n",
      "Epoch 83/100\n",
      "5119/5119 [==============================] - 1s 194us/step - loss: 0.1052 - acc: 0.9656 - val_loss: 0.0741 - val_acc: 0.9713\n",
      "Epoch 84/100\n",
      "5119/5119 [==============================] - 1s 193us/step - loss: 0.1080 - acc: 0.9611 - val_loss: 0.1466 - val_acc: 0.9472\n",
      "Epoch 85/100\n",
      "5119/5119 [==============================] - 1s 232us/step - loss: 0.1177 - acc: 0.9611 - val_loss: 0.0863 - val_acc: 0.9645\n",
      "Epoch 86/100\n",
      "5119/5119 [==============================] - 1s 201us/step - loss: 0.1081 - acc: 0.9594 - val_loss: 0.0764 - val_acc: 0.9722\n",
      "Epoch 87/100\n",
      "5119/5119 [==============================] - 1s 199us/step - loss: 0.1095 - acc: 0.9617 - val_loss: 0.1284 - val_acc: 0.9522\n",
      "Epoch 88/100\n",
      "5119/5119 [==============================] - 1s 221us/step - loss: 0.1136 - acc: 0.9592 - val_loss: 0.0799 - val_acc: 0.9727\n",
      "Epoch 89/100\n",
      "5119/5119 [==============================] - 1s 210us/step - loss: 0.1067 - acc: 0.9621 - val_loss: 0.0704 - val_acc: 0.9772\n",
      "Epoch 90/100\n",
      "5119/5119 [==============================] - 1s 215us/step - loss: 0.1129 - acc: 0.9586 - val_loss: 0.0753 - val_acc: 0.9795\n",
      "Epoch 91/100\n",
      "5119/5119 [==============================] - 1s 231us/step - loss: 0.1087 - acc: 0.9605 - val_loss: 0.0828 - val_acc: 0.9722\n",
      "Epoch 92/100\n",
      "5119/5119 [==============================] - 1s 198us/step - loss: 0.1047 - acc: 0.9625 - val_loss: 0.0746 - val_acc: 0.9727\n",
      "Epoch 93/100\n",
      "5119/5119 [==============================] - 1s 202us/step - loss: 0.1125 - acc: 0.9605 - val_loss: 0.0791 - val_acc: 0.9736\n",
      "Epoch 94/100\n",
      "5119/5119 [==============================] - 1s 194us/step - loss: 0.1051 - acc: 0.9621 - val_loss: 0.0696 - val_acc: 0.9763\n",
      "Epoch 95/100\n",
      "5119/5119 [==============================] - 1s 192us/step - loss: 0.1043 - acc: 0.9607 - val_loss: 0.0694 - val_acc: 0.9754\n",
      "Epoch 96/100\n",
      "5119/5119 [==============================] - 1s 204us/step - loss: 0.1192 - acc: 0.9588 - val_loss: 0.0738 - val_acc: 0.9749\n",
      "Epoch 97/100\n",
      "5119/5119 [==============================] - 1s 194us/step - loss: 0.1151 - acc: 0.9576 - val_loss: 0.0802 - val_acc: 0.9740\n",
      "Epoch 98/100\n",
      "5119/5119 [==============================] - 1s 202us/step - loss: 0.1079 - acc: 0.9609 - val_loss: 0.0734 - val_acc: 0.9754\n",
      "Epoch 99/100\n",
      "5119/5119 [==============================] - 1s 209us/step - loss: 0.0998 - acc: 0.9637 - val_loss: 0.0872 - val_acc: 0.9681\n",
      "Epoch 100/100\n",
      "5119/5119 [==============================] - 1s 193us/step - loss: 0.1087 - acc: 0.9617 - val_loss: 0.0771 - val_acc: 0.9690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x101b706dd8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model/model_9_positions.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
